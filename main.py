# 1. Imports essenciais
import streamlit as st
import os
import google.generativeai as genai
from dotenv import load_dotenv

# 2. ConfiguraÃ§Ã£o da PÃ¡gina (Aba do Navegador)
# Deve ser o primeiro comando Streamlit do seu script!
# ConfiguraÃ§Ã£o da pÃ¡gina (deve ser a primeira coisa depois dos imports)
# Esta funÃ§Ã£o permite personalizar a aparÃªncia da aplicaÃ§Ã£o
st.set_page_config(
    page_title="Chatbot com Google Gemini",  # TÃ­tulo que aparece na aba do navegador
    page_icon="ğŸ¤–",                          # Ãcone da aba do navegador
    layout="wide",                           # Layout amplo ou centralizado
    initial_sidebar_state="expanded"         # Sidebar expandida ou colapsada
)

# 3. Carregamento e VerificaÃ§Ã£o da API Key
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Verificar se a API Key estÃ¡ presente
if not GEMINI_API_KEY:
    st.error("ğŸ”‘ API Key nÃ£o encontrada. Verifique o arquivo .env.")
    st.stop()

# 4. ConfiguraÃ§Ã£o da API do Gemini
genai.configure(api_key=GEMINI_API_KEY)

# FunÃ§Ã£o para INICIALIZAR o modelo com configuraÃ§Ãµes especÃ­ficas
def init_gemini():
    generation_config = {
        "temperature": 0.7,
        "top_p": 0.8,
        "top_k": 40,
        "max_output_tokens": 2048,
    }
    
    model = genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        generation_config=generation_config
    )
    return model

# FunÃ§Ã£o para gerar resposta do chatbot
def generate_response(model, prompt):
    """
    FunÃ§Ã£o para GERAR uma resposta do modelo Gemini, com tratamento de erros.
    
    Args:
        model: O modelo Gemini inicializado
        prompt (str): A pergunta/prompt do usuÃ¡rio
    
    Returns:
        str: A resposta gerada pelo modelo ou mensagem de erro
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# ConfiguraÃ§Ã£o da sidebar apenas com estatÃ­sticas
with st.sidebar:
    st.header("âš™ï¸ ConfiguraÃ§Ãµes")
    
    if st.button("ğŸ—‘ï¸ Limpar Conversa"):
        if 'messages' in st.session_state:
            st.session_state.messages = []
            st.rerun()
    
    st.divider()
    st.subheader("ğŸ“Š EstatÃ­sticas")
    if 'messages' in st.session_state:
        st.metric("Mensagens trocadas", len(st.session_state.messages))
    else:
        st.metric("Mensagens trocadas", 0)

# Inicializar o modelo
if 'model' not in st.session_state:
    with st.spinner("ğŸ”„ Inicializando modelo Gemini..."):
        st.session_state.model = init_gemini()

# Interface do usuÃ¡rio principal
st.title("ğŸ¤– Chatbot com Google Gemini")
st.write("Bem-vindo ao seu assistente virtual inteligente!")

# Exemplo de como os alunos podem personalizar ainda mais
st.markdown("""
<style>
    .main > div {
        padding-top: 2rem;
    }
</style>
""", unsafe_allow_html=True)

# 1. Inicializa o histÃ³rico de mensagens se for a primeira execuÃ§Ã£o
if 'messages' not in st.session_state:
    st.session_state.messages = []
    # Mensagem de boas-vindas personalizada
    st.session_state.messages.append({
        "role": "assistant",
        "content": """ğŸ‘‹ OlÃ¡! Eu sou seu assistente virtual powered by Google Gemini. 

Posso ajudar vocÃª com:
- â“ Responder perguntas gerais
- ğŸ’» Explicar conceitos de programaÃ§Ã£o
- ğŸ“ Criar e revisar textos
- ğŸ§® Resolver problemas matemÃ¡ticos
- ğŸ¨ Ideias criativas

Como posso ajudar vocÃª hoje?"""
    })

# 2. Loop que exibe CADA mensagem guardada no histÃ³rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input do usuÃ¡rio
if prompt := st.chat_input("ğŸ’¬ Digite sua mensagem aqui..."):
    # Adicionar mensagem do usuÃ¡rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Gerar resposta do assistente
    with st.chat_message("assistant"):
        with st.spinner("ğŸ¤” Pensando..."):
            response = generate_response(st.session_state.model, prompt)
            st.markdown(response)
    
    # Adicionar resposta ao histÃ³rico
    st.session_state.messages.append({"role": "assistant", "content": response})